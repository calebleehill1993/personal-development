{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to give us an opportunity to test what we've been learning in the Coursera course. The dataset contains information about cars and how much they sold for. We want to be able to predict the price of cars using Multiple Linear Regression."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "df = pd.read_csv('coursera_machine_learning_specialization/course_1_supervised_machine_learning:_regression_and_classification/week_2/custom_project_cars/cars.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the numberic columns\n",
    "df = df.select_dtypes(include=np.number)\n",
    "# Get rid of the ID column\n",
    "df.drop(columns=['ID'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be following along the following article walking through exploritory data analysis with Pandas before doing the regression. https://www.kaggle.com/code/kashnitsky/topic-1-exploratory-data-analysis-with-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(df.corr(numeric_only=True))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things that I'm noticing fromt the correlation matrix.\n",
    "- Length, width, and weight are very correlated\n",
    "- gas milage for city and highway are very correlated\n",
    "- horsepower is correlated with enginesize\n",
    "- price seems to be correlated with wheelbase, width, length, weight, enginesize, boreratio, horsepower, citympg, highwaympg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have some idea of what features we want to use, let's drop unimportant features and do some other feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df.copy()\n",
    "df_select['mpg'] = np.mean((df_select['citympg'], df_select['highwaympg']), axis=0)\n",
    "df_select = df_select.loc[:, ['curbweight', 'boreratio', 'horsepower', 'mpg', 'price']]\n",
    "df_select.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing some modelling, let's get a training and test set. We don't need a validation set as we're not really using other model types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all, test_all = train_test_split(df, test_size=0.2, random_state=1)\n",
    "train_select, test_select = train_test_split(df_select, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_all = LinearRegression()\n",
    "linear_model_select = LinearRegression()\n",
    "\n",
    "linear_model_all.fit(train_all.loc[:, :'highwaympg'], train_all.loc[:, 'price'])\n",
    "linear_model_select.fit(train_select.loc[:, :'mpg'], train_select.loc[:, 'price'])\n",
    "\n",
    "b_all = linear_model_all.intercept_\n",
    "w_all = linear_model_all.coef_\n",
    "b_select = linear_model_select.intercept_\n",
    "w_select = linear_model_select.coef_\n",
    "\n",
    "print('ALL FEATURES:')\n",
    "for coef in list(zip(linear_model_all.feature_names_in_, w_all)):\n",
    "    print(coef)\n",
    "print()\n",
    "print('SELECT FEATURES:')\n",
    "for coef in list(zip(linear_model_select.feature_names_in_, w_select)):\n",
    "    print(coef)\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"b_all = {b_all:0.2f}\")\n",
    "print(f\"b_select = {b_select:0.2f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "test_all_pred = linear_model_all.predict(test_all.loc[:, :'highwaympg'])\n",
    "test_select_pred = linear_model_select.predict(test_select.loc[:, :'mpg'])\n",
    "\n",
    "print(f\"training r2 score all = {r2_score(linear_model_all.predict(train_all.loc[:, :'highwaympg']), train_all.loc[:, 'price'])}\")\n",
    "print(f\"training r2 score select = {r2_score(linear_model_select.predict(train_select.loc[:, :'mpg']), train_select.loc[:, 'price'])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"r2 score all = {r2_score(test_all_pred, test_all.loc[:, 'price'])}\")\n",
    "print(f\"r2 score select = {r2_score(test_select_pred, test_select.loc[:, 'price'])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model using all the features seems to overfit to the training data. We can see this buy the fact that the r2 value for the training set is much higher than the r2 for the test set. Also, the selective model seems to perform better overall with the test set, which is a plus. We could do furter feature engineering and selection, but this will be enough for the purposes of practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
